{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Replace 'your_file.json' with your actual JSON file name\n",
    "file_name = \"vectorized_summary.json\"\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open(file_name, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Now 'data' is a Python dictionary containing the contents of the JSON file\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of your dictionaries\n",
    "data_list = data\n",
    "\n",
    "# Extract vectors from the dictionaries\n",
    "vectors = [item[\"vector\"] for item in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usearch.BatchMatches(689 across 689 queries)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# ANYA\n",
    "from usearch.index import Index\n",
    "\n",
    "# Your list of vectors\n",
    "your_vectors = vectors\n",
    "\n",
    "# 1. Create an Index and Cluster Vectors\n",
    "index = Index(ndim=len(your_vectors[0]))  # Assuming all vectors have the same dimension\n",
    "\n",
    "for key, vector in enumerate(your_vectors):\n",
    "    index.add(key, np.array(vector))\n",
    "\n",
    "clustering = index.cluster(max_count=100)  # Perform clustering\n",
    "clustering.matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster indices for each vector: [ 5  0  5  9  0  9  2  5  9  5  2  9  0  5  5  5  0  0  2  9  9  9  2  2\n",
      "  0  2  2  5  6  2  6  6  1  2  0  2  9  5  2  5  6  9  2  0  5  0  9  0\n",
      "  2  5  6  0  6  6  6  0  2  6  0  9  0  9  0  5  9  5  5  5  0  0  2 12\n",
      "  0  5  9  9  5 10  2  9  2  2  5  5  0  5  5  8  5  5  5  0  9  5  5  0\n",
      "  9  5  2  5  5  5  5  5  5  5  5  5  2  5  5  5 13  0  2  1  9  9  1  5\n",
      "  2  5  5  0  9 12  5  5  9  2  0  2  9  5  9  0 13  5  5  0  9  9  9  9\n",
      "  5  0  7  0  9  0  0  0  9  0  9  2  2  2  5  2  5  2  2  7  2  2  5  0\n",
      "  5  5  9  9  5  0  5  5  0  9  5  5  7  0  0  9  9  5  5  9  2  7  2  5\n",
      "  5  5  0  0  0  9  9 13  5  2  2  9  9  9 12 13  0  0  9  5  0  9  9  9\n",
      "  0  2  5 12  5  9  2  2  2  2  2  5  9 14  2  9  9  2  0  2  2  2  2  2\n",
      "  5  2  9  2  2  5  2  2  2 14  9  2 12  9  0 13 13 12  0  9  2  8  0 13\n",
      "  2  0  0 14  5  2  0  0  9  2  9  2  9  2  2 13  0  2  9 13 13  5  9 13\n",
      " 13  9  5  9  5  1  9  5  0  2  0 13  0  0  9  1  0  2 11 13  1  5  3  0\n",
      "  3  0  3 11 11  5  1  0 11  0  0  2  1  2  2 11  9  2  9 11  0  0 11  3\n",
      "  1  0  2  0 11  2  1  9  9  9 11  3  9  1  3  0  5 11 11  0 11 11  1 11\n",
      " 11  9  2  2 14 13  1 14  9  2  9  2  1  2  2  8  0  1 13  1  0  0  2  2\n",
      "  9  8  1  9  3  1  3  2  3  1  3  3  9  9  2  2  3  0  3  5  3  0  0 12\n",
      "  3  8  3  2  1 13  3 12 13  8  3 13 12 12 12 13  3  0 12  0 13  3  0  2\n",
      "  3  1  2  2 13  3 13  0  9  3  8 13  2  1  0  0  3  3  0  8 13  0  8  8\n",
      "  1  8  8  0  2  8  2  2  8  8  8 14  8 12 13  2  9  8  2  9 13  2 13  9\n",
      "  9  8  9  8 13  8 13 13  9 13  2  8  9 13  8  0  8  8  4  8  0  0  8  8\n",
      "  8  9  0  0  8  8  8  8 13  8  8  8  8  9 13  8  8 13  8  2  8  8  8  8\n",
      "  8 12 12 12  8 12 12 12  8  9  0 13  8  1 13 13 13  8 12  8 13 12  0  0\n",
      " 13  7 12  9  7  9 13 12 14  0  0  1  7  7  7  0  0  9  7  0  7  7  9  7\n",
      " 14 14  0  1  9 14 14 14  4  9  4 14  0  0 14  9 13 14  0  1  9  9  1 14\n",
      " 14 13 14  1 14 14 14 14  1 14 14 14 14  1 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 14 14  4 14 14 14 14 14  2 14 14 14 14 14 14 14\n",
      " 14 14 14 14 14 14 14 14 13  4 14  4 14 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'data' is your matrix of vectors. Replace this with your actual data.\n",
    "# Example: data = np.array([[1, 2], [2, 3], [1, 4], [5, 6], [7, 8], [9, 10]])\n",
    "\n",
    "\n",
    "# data = np.array(vectors * 10)\n",
    "data = np.vstack(index.get(np.array(index.keys), dtype=np.float32))\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = 15\n",
    "\n",
    "# Compute K-Means with 'num_clusters' clusters\n",
    "centroids, _ = kmeans(data, num_clusters)\n",
    "\n",
    "# Assign each sample to a cluster\n",
    "idx, _ = vq(data, centroids)\n",
    "\n",
    "# 'idx' is an array of cluster indices corresponding to each vector in your matrix\n",
    "print(\"Cluster indices for each vector:\", idx)\n",
    "\n",
    "\n",
    "### -----\n",
    "# def is_vector_in_cluster(vector, centroids, threshold):\n",
    "#     # Normalize or preprocess the vector if necessary\n",
    "#     # vector = preprocess(vector)  # Uncomment and define preprocess if needed\n",
    "\n",
    "#     # Find the nearest centroid and the distance to it\n",
    "#     centroid_idx, distance = vq(np.array([vector]), centroids)\n",
    "\n",
    "#     # Check if the distance is within the threshold\n",
    "#     is_within_cluster = distance[0] <= threshold\n",
    "#     return is_within_cluster, centroid_idx[0]\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# new_vector = np.array(vectors[0])  # Replace with your new vector\n",
    "# threshold = 150  # Define your threshold\n",
    "\n",
    "# is_in_cluster, cluster_idx = is_vector_in_cluster(new_vector, centroids, threshold)\n",
    "# print(\"Is in cluster:\", is_in_cluster, \"Cluster index:\", cluster_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Assuming 'idx' is the array of cluster indices you obtained from clustering\n",
    "clustered_data = [[] for _ in range(num_clusters)]\n",
    "\n",
    "# Group data items by their cluster, removing the 'vector' field\n",
    "for i, item in enumerate(data_list):\n",
    "    cluster_index = idx[i]\n",
    "    item_without_vector = item.copy()  # Copy to avoid modifying the original data\n",
    "    item_without_vector.pop(\"vector\", None)  # Remove the 'vector' field\n",
    "    clustered_data[cluster_index].append(item_without_vector)\n",
    "\n",
    "# Select one random item from each cluster and compile links\n",
    "random_items = []\n",
    "cluster_links = []\n",
    "\n",
    "for cluster in clustered_data:\n",
    "    random_item = random.choice(\n",
    "        cluster\n",
    "    ).copy()  # Copy to avoid modifying the original data\n",
    "    random_item.pop(\"vector\", None)  # Remove the 'vector' field\n",
    "    random_items.append(random_item)\n",
    "\n",
    "    links = [item[\"link\"] for item in cluster]\n",
    "    cluster_links.append(links)\n",
    "\n",
    "# random_items now contains one random item from each cluster\n",
    "# cluster_links is a list of lists, each containing the links of all items in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the final list of cluster results\n",
    "cluster_results = []\n",
    "\n",
    "for i, cluster in enumerate(clustered_data):\n",
    "    if cluster:  # Check if the cluster is not empty\n",
    "        # Select a random item for title, description, and date\n",
    "        random_item = random.choice(cluster)\n",
    "\n",
    "        # Create the cluster dictionary\n",
    "        cluster_dict = {\n",
    "            \"title\": random_item[\"title\"],\n",
    "            \"description\": random_item[\"summary\"],  # Rename 'excerpt' to 'description'\n",
    "            \"date\": random_item[\"published_date\"],  # Rename 'published_date' to 'date'\n",
    "            \"sources\": cluster_links[i],  # Add all links in the cluster\n",
    "        }\n",
    "\n",
    "        # Add the dictionary to the results list\n",
    "        cluster_results.append(cluster_dict)\n",
    "\n",
    "# 'cluster_results' now contains a list of dictionaries, each representing a cluster with the desired fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster results saved to cluster_results_15.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Prepare the final list of cluster results (assuming this is already done)\n",
    "# cluster_results = [...]\n",
    "\n",
    "# Specify the filename for the JSON file\n",
    "filename = f\"cluster_results_{num_clusters}.json\"\n",
    "\n",
    "# Write the cluster results to a JSON file\n",
    "with open(filename, \"w\") as file:\n",
    "    json.dump(cluster_results, file, indent=4)\n",
    "\n",
    "print(f\"Cluster results saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sophos",
   "language": "python",
   "name": "sophos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
